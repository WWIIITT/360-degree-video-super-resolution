{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBVwYU1E2rqs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n",
        "\n",
        "# Clean previous installations\n",
        "!rm -rf Real-ESRGAN\n",
        "!pip uninstall -y torch torchvision basicsr facexlib gfpgan\n",
        "\n",
        "# Install compatible dependencies\n",
        "!pip install torch==1.13.1 torchvision==0.13.1\n",
        "!pip install numpy==1.23.5\n",
        "\n",
        "# Clone and set up Real-ESRGAN\n",
        "!git clone https://github.com/xinntao/Real-ESRGAN.git\n",
        "%cd /content/Real-ESRGAN\n",
        "\n",
        "# FIX: Install requirements BEFORE setup\n",
        "!pip install -r requirements.txt\n",
        "!pip install basicsr==1.4.2 facexlib==0.3.0 gfpgan==1.3.8\n",
        "!pip install -U opencv-python opencv-contrib-python\n",
        "\n",
        "# FIX: Use standard install instead of develop\n",
        "!python setup.py install\n",
        "\n",
        "# Download models\n",
        "!wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth -P experiments/pretrained_models\n",
        "\n",
        "# Patch broken import\n",
        "!sed -i \"s/from torchvision.transforms.functional_tensor import/from torchvision.transforms.functional import/g\" /usr/local/lib/python3.*/dist-packages/basicsr/data/degradations.py\n",
        "\n",
        "# Clone and set up GFPGAN\n",
        "%cd /content\n",
        "!git clone https://github.com/TencentARC/GFPGAN.git\n",
        "%cd /content/GFPGAN\n",
        "\n",
        "# FIX: Install requirements BEFORE setup\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import subprocess\n",
        "\n",
        "# Upload the .insv video\n",
        "uploaded = files.upload()\n",
        "input_video = next(iter(uploaded))\n",
        "\n",
        "# Extract frame rate\n",
        "result = subprocess.run(['ffprobe', '-v', 'error', '-select_streams', 'v:0',\n",
        "                         '-show_entries', 'stream=r_frame_rate',\n",
        "                         '-of', 'default=noprint_wrappers=1:nokey=1',\n",
        "                         input_video],\n",
        "                        stdout=subprocess.PIPE, text=True)\n",
        "frame_rate = result.stdout.strip()\n",
        "\n",
        "# Create directory for frames\n",
        "!mkdir -p /content/frames\n",
        "\n",
        "# Extract frames\n",
        "!ffmpeg -i {input_video} /content/frames/%04d.png -hide_banner -loglevel error\n",
        "\n",
        "# Extract audio\n",
        "!ffmpeg -i {input_video} -vn -acodec copy /content/audio.aac -hide_banner -loglevel error\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Tuning parameters\n",
        "USE_REALESRGAN_FACE_ENHANCE = True\n",
        "GFPGAN_WEIGHT = 0.2\n",
        "BLUR_KERNEL_SIZE = 151\n",
        "BLENDING_ALPHA = 0.3\n",
        "\n",
        "# Set absolute paths\n",
        "BASE_DIR = Path(\"/content\")\n",
        "REALESRGAN_DIR = BASE_DIR / \"Real-ESRGAN\"\n",
        "GFPGAN_DIR = BASE_DIR / \"GFPGAN\"\n",
        "\n",
        "# Create output directories\n",
        "output_dir = REALESRGAN_DIR / \"results\"\n",
        "(output_dir / \"upscaled\").mkdir(parents=True, exist_ok=True)\n",
        "(output_dir / \"gfpgan_output\" / \"restored_imgs\").mkdir(parents=True, exist_ok=True)\n",
        "(output_dir / \"final\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "frame_list = sorted(glob.glob(str(BASE_DIR / \"frames\" / \"*.png\")))\n",
        "print(f\"Found {len(frame_list)} frames to process\")\n",
        "\n",
        "for frame_path in frame_list:\n",
        "    frame_path = Path(frame_path)\n",
        "    frame_name = frame_path.name\n",
        "    print(f\"\\nProcessing {frame_name}...\")\n",
        "\n",
        "    # ======================================================================\n",
        "    # 1. REAL-ESRGAN UPSAMPLING\n",
        "    # ======================================================================\n",
        "    upscaled_filename = frame_name.replace('.png', '_upscaled.png')\n",
        "    upscaled_path = output_dir / \"upscaled\" / upscaled_filename\n",
        "\n",
        "    if not upscaled_path.exists():\n",
        "        face_enhance_flag = \"--face_enhance\" if USE_REALESRGAN_FACE_ENHANCE else \"\"\n",
        "        cmd = [\n",
        "            sys.executable, str(REALESRGAN_DIR / \"inference_realesrgan.py\"),\n",
        "            \"-n\", \"RealESRGAN_x4plus.pth\",\n",
        "            \"-i\", str(frame_path),\n",
        "            \"--outscale\", \"4\",\n",
        "            \"--output\", str(output_dir / \"upscaled\"),\n",
        "            \"--suffix\", \"upscaled\"\n",
        "        ]\n",
        "        if face_enhance_flag:\n",
        "            cmd.append(face_enhance_flag)\n",
        "\n",
        "        print(\"  Running RealESRGAN...\")\n",
        "\n",
        "        # Set PYTHONPATH to include both modules\n",
        "        env = os.environ.copy()\n",
        "        env[\"PYTHONPATH\"] = f\"{REALESRGAN_DIR}:{GFPGAN_DIR}:{env.get('PYTHONPATH', '')}\"\n",
        "\n",
        "        result = subprocess.run(cmd, env=env, capture_output=True, text=True)\n",
        "\n",
        "        if result.returncode != 0:\n",
        "            print(f\"  ❗ RealESRGAN failed for {frame_name}\")\n",
        "            print(f\"  Error: {result.stderr[:500]}\")\n",
        "            continue\n",
        "\n",
        "        # Verify output\n",
        "        if not upscaled_path.exists():\n",
        "            # Try to find any output file\n",
        "            possible_files = list((output_dir / \"upscaled\").glob(\"*.png\"))\n",
        "            if possible_files:\n",
        "                actual_path = possible_files[0]\n",
        "                print(f\"  Found alternative output: {actual_path}\")\n",
        "                os.rename(str(actual_path), str(upscaled_path))\n",
        "            else:\n",
        "                print(f\"  ❗ No output created in {output_dir / 'upscaled'}\")\n",
        "                continue\n",
        "\n",
        "    # ======================================================================\n",
        "    # 2. GFPGAN ENHANCEMENT\n",
        "    # ======================================================================\n",
        "    gfpgan_path = output_dir / \"gfpgan_output\" / \"restored_imgs\" / upscaled_filename\n",
        "\n",
        "    if not gfpgan_path.exists():\n",
        "        cmd = [\n",
        "            sys.executable, str(GFPGAN_DIR / \"inference_gfpgan.py\"),\n",
        "            \"-i\", str(upscaled_path),\n",
        "            \"-o\", str(output_dir / \"gfpgan_output\"),\n",
        "            \"-v\", \"1.4\",\n",
        "            \"-s\", \"1\",\n",
        "            \"--weight\", str(GFPGAN_WEIGHT),\n",
        "            \"--bg_upsampler\", \"realesrgan\"\n",
        "        ]\n",
        "        print(\"  Running GFPGAN...\")\n",
        "\n",
        "        # Set PYTHONPATH to include both modules\n",
        "        env = os.environ.copy()\n",
        "        env[\"PYTHONPATH\"] = f\"{REALESRGAN_DIR}:{GFPGAN_DIR}:{env.get('PYTHONPATH', '')}\"\n",
        "\n",
        "        result = subprocess.run(cmd, env=env, capture_output=True, text=True)\n",
        "\n",
        "        if result.returncode != 0:\n",
        "            print(f\"  ❗ GFPGAN failed: {result.stderr[:500]}\")\n",
        "            # Try to find GFPGAN output in alternative location\n",
        "            possible_gfpgan = list((output_dir / \"gfpgan_output\").rglob(\"*.png\"))\n",
        "            if possible_gfpgan:\n",
        "                actual_path = possible_gfpgan[0]\n",
        "                print(f\"  Found GFPGAN output at: {actual_path}\")\n",
        "                gfpgan_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "                os.rename(str(actual_path), str(gfpgan_path))\n",
        "\n",
        "    # ======================================================================\n",
        "    # 3. PROCESS IMAGES\n",
        "    # ======================================================================\n",
        "    original_upscaled = cv2.imread(str(upscaled_path))\n",
        "    if original_upscaled is None:\n",
        "        print(f\"  ❗ Failed to load upscaled image\")\n",
        "        continue\n",
        "\n",
        "    # Use GFPGAN output if available, otherwise use original\n",
        "    if gfpgan_path.exists():\n",
        "        enhanced = cv2.imread(str(gfpgan_path))\n",
        "    else:\n",
        "        enhanced = original_upscaled.copy()\n",
        "\n",
        "    # Resize if needed\n",
        "    if enhanced.shape != original_upscaled.shape:\n",
        "        enhanced = cv2.resize(enhanced, (original_upscaled.shape[1], original_upscaled.shape[0]))\n",
        "\n",
        "    # ======================================================================\n",
        "    # 4. FACE DETECTION AND BLENDING\n",
        "    # ======================================================================\n",
        "    print(\"  Blending results...\")\n",
        "    balanced_result = original_upscaled.copy()\n",
        "    gray = cv2.cvtColor(original_upscaled, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Initialize face detector\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.1, 4, minSize=(50, 50))\n",
        "\n",
        "    if len(faces) > 0:\n",
        "        print(f\"  Detected {len(faces)} faces\")\n",
        "        mask = np.zeros(gray.shape[:2], dtype=np.float32)\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            # Expand face area for blending\n",
        "            y_exp = max(0, y - int(h * 0.25))\n",
        "            x_exp = max(0, x - int(w * 0.25))\n",
        "            h_exp = min(gray.shape[0] - y_exp, int(h * 1.5))\n",
        "            w_exp = min(gray.shape[1] - x_exp, int(w * 1.5))\n",
        "\n",
        "            # Create elliptical mask\n",
        "            center = (x_exp + w_exp//2, y_exp + h_exp//2)\n",
        "            axes = (int(w_exp*0.5), int(h_exp*0.5))\n",
        "            cv2.ellipse(mask, center, axes, 0, 0, 360, 1.0, -1)\n",
        "\n",
        "        # Smooth mask\n",
        "        mask = cv2.GaussianBlur(mask, (BLUR_KERNEL_SIZE, BLUR_KERNEL_SIZE), 0)\n",
        "        mask = np.clip(mask, 0, 1)\n",
        "        mask_3d = np.dstack([mask, mask, mask])\n",
        "\n",
        "        # Blend images\n",
        "        original_float = original_upscaled.astype(np.float32)\n",
        "        enhanced_float = enhanced.astype(np.float32)\n",
        "        blended = original_float * (1 - mask_3d * BLENDING_ALPHA) + enhanced_float * (mask_3d * BLENDING_ALPHA)\n",
        "        balanced_result = np.clip(blended, 0, 255).astype(np.uint8)\n",
        "    else:\n",
        "        print(\"  No faces detected - applying global blend\")\n",
        "        balanced_result = cv2.addWeighted(original_upscaled, 1 - BLENDING_ALPHA, enhanced, BLENDING_ALPHA, 0)\n",
        "\n",
        "    # ======================================================================\n",
        "    # 5. POST-PROCESSING AND SAVING\n",
        "    # ======================================================================\n",
        "    print(\"  Final processing...\")\n",
        "    # CLAHE for contrast enhancement\n",
        "    lab = cv2.cvtColor(balanced_result, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(8,8))\n",
        "    l = clahe.apply(l)\n",
        "    balanced_result = cv2.merge((l, a, b))\n",
        "    balanced_result = cv2.cvtColor(balanced_result, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Gentle noise reduction\n",
        "    balanced_result = cv2.bilateralFilter(balanced_result, 5, 25, 25)\n",
        "\n",
        "    # Save final frame\n",
        "    final_path = output_dir / \"final\" / frame_name\n",
        "    cv2.imwrite(str(final_path), balanced_result)\n",
        "    print(f\"  ✅ Saved enhanced frame: {final_path}\")\n",
        "\n",
        "print(\"\\nProcessing complete!\")\n"
      ],
      "metadata": {
        "id": "nvzk5rSw26AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# VIDEO RECONSTRUCTION\n",
        "# ===================================================================\n",
        "print(\"\\nReconstructing video...\")\n",
        "final_video = \"enhanced_video.mp4\"\n",
        "!ffmpeg -framerate {frame_rate} -i /content/Real-ESRGAN/results/final/%04d.png \\\n",
        "        -i /content/audio.aac \\\n",
        "        -c:v libx264 -preset slow -crf 18 \\\n",
        "        -c:a aac -b:a 192k \\\n",
        "        -pix_fmt yuv420p {final_video} -hide_banner -loglevel error\n",
        "\n",
        "print(\"Final video saved as enhanced_video.mp4\")\n",
        "files.download(final_video)"
      ],
      "metadata": {
        "id": "OIg9ha2k4Rlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lB9LJ47G4TdF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}